{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c952a3a-f0e7-458e-88db-b4f3c043095b",
   "metadata": {},
   "source": [
    "## Step 1:\n",
    "### Loading data into different directories based on its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab613b0e-c4d8-4e57-bac5-56fddeb09b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from shutil import copy, rmtree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e132e7-2f71-418c-977f-b9f22789be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e6f418f-9bcd-422a-bdf9-8896af318a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put this notebook in the same file where you put the metadata.csv and the image files \n",
    "train_df = pd.read_csv('train_metadata.csv') # the orginal file: HAM10000_metadata.csv, I changed its name for simplicity\n",
    "test_df = pd.read_csv('test_metadata.csv') # the orginal file:ISIC2018_Task3_Test_GroundTruth.csv, I changed its name for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6126640c-3b64-4f44-9400-5ead9ddbabdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "train_dir = os.path.join(cwd, 'train_dir')\n",
    "test_dir = os.path.join(cwd, 'test_dir')\n",
    "os.mkdir(train_dir)\n",
    "os.mkdir(test_dir)\n",
    "train_list = list(train_df['image_id'])\n",
    "test_list = list(test_df['image_id'])\n",
    "for i in targetnames:\n",
    "    directory1=train_dir+'/'+i\n",
    "    directory2=test_dir+'/'+i\n",
    "    os.mkdir(directory1)\n",
    "    os.mkdir(directory2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef24748c-dea3-47ff-a86d-482d802e99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.set_index('image_id', inplace=True)\n",
    "test_df.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f97a350-afb1-4e7e-9408-1f775b1c662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in train_list:\n",
    "    file_name = image+'.jpg'\n",
    "    label = train_df.loc[image, 'dx']\n",
    "\n",
    "    # path of source image\n",
    "    # I combined the orginal file ```HAM10000_images_part_1``` and ```HAM10000_images_part_2```,\n",
    "    # named the combined file as ```train```\n",
    "    source = os.path.join(cwd, 'train', file_name)   \n",
    "    if not os.path.exists(source):\n",
    "        print(f\"Image {file_name} not found. Skipping...\")\n",
    "        continue\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(train_dir, label, file_name)\n",
    "\n",
    "    copy(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79e3f5ff-3950-45f4-bfe6-3d6d88554092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ISIC_0035068.jpg not found. Skipping...\n"
     ]
    }
   ],
   "source": [
    "for image in test_list:\n",
    "    file_name = image+'.jpg'\n",
    "    label = test_df.loc[image, 'dx']\n",
    "\n",
    "    # path of source image\n",
    "    # I renamed the file ```ISIC2018_Task3_Test_Images``` as ```test```\n",
    "    source = os.path.join(cwd, 'test', file_name)\n",
    "    if not os.path.exists(source):\n",
    "        print(f\"Image {file_name} not found. Skipping...\")\n",
    "        continue\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(test_dir, label, file_name)\n",
    "\n",
    "    copy(source, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76790d0-0ebc-4641-9035-801d44501da3",
   "metadata": {},
   "source": [
    "## Step 2:\n",
    "### Split data into train set and val set\n",
    "### Data Augmentation on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c079d71-c609-4f31-a4f9-a7c6fa422f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from shutil import copy, rmtree \n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a325e5ea-cec6-4313-80c6-da74936fb4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_file(file_path: str):\n",
    "    if os.path.exists(file_path):\n",
    "        rmtree(file_path)\n",
    "    os.makedirs(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8301a1a-8c1d-4390-90f7-739eda4fb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "random.seed(0)\n",
    "split_rate = 0.11\n",
    "\n",
    "cwd = os.getcwd()\n",
    "data_root = os.path.abspath(os.path.join(cwd))\n",
    "origin_data_path_0 = os.path.join(data_root, \"train_dir\")\n",
    "assert os.path.exists(origin_data_path_0), \"path '{}' does not exist.\".format(origin_data_path_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1482ddbd-8ae4-4aaf-86b6-fe198c5d41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class = [cla for cla in os.listdir(origin_data_path_0)\n",
    "                if os.path.isdir(os.path.join(origin_data_path_0, cla))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c59d5ce6-7a8a-4e07-8fa1-30ea6ab7190b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42808d6f-8047-4af3-b0cd-0e64db10938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sm_root = os.path.join(data_root, \"train_sm_dir\")\n",
    "mk_file(train_sm_root)\n",
    "for cla in data_class:\n",
    "    mk_file(os.path.join(train_sm_root, cla))\n",
    "    \n",
    "val_root = os.path.join(data_root, \"val_dir\")\n",
    "mk_file(val_root)\n",
    "for cla in data_class:\n",
    "    mk_file(os.path.join(val_root, cla))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6e58906-8e97-4e10-a296-79d2a72a07b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[akiec] processing [327/327]\n",
      "[bcc] processing [514/514]\n",
      "[bkl] processing [1099/1099]\n",
      "[df] processing [115/115]\n",
      "[mel] processing [1113/1113]\n",
      "[nv] processing [6705/6705]\n",
      "[vasc] processing [142/142]\n",
      "processing 10015 done!\n"
     ]
    }
   ],
   "source": [
    "total_num = 0\n",
    "for cla in data_class:\n",
    "    cla_path = os.path.join(origin_data_path_0, cla)\n",
    "    images = os.listdir(cla_path)\n",
    "    num = len(images)\n",
    "    total_num += num\n",
    "    eval_index = random.sample(images, k=int(num*split_rate))\n",
    "    for index, image in enumerate(images):\n",
    "        if image in eval_index:\n",
    "            image_path = os.path.join(cla_path, image)\n",
    "            new_path = os.path.join(val_root, cla)\n",
    "            copy(image_path, new_path)\n",
    "        else:\n",
    "            image_path = os.path.join(cla_path, image)\n",
    "            new_path = os.path.join(train_sm_root, cla)\n",
    "            copy(image_path, new_path)\n",
    "        print(\"\\r[{}] processing [{}/{}]\".format(cla, index+1, num), end=\"\")  # processing bar\n",
    "    print()\n",
    "\n",
    "print(f\"processing {total_num} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e85d11d-d18e-4a64-b689-707896880ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source directory\n",
    "cwd = os.getcwd()\n",
    "data_root = os.path.abspath(os.path.join(cwd))\n",
    "origin_data_path = os.path.join(data_root, \"train_sm_dir\")\n",
    "assert os.path.exists(origin_data_path), \"path '{}' does not exist.\".format(origin_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fafca7d-1352-4f4e-9104-e5005fa9c028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_class = [cla for cla in os.listdir(origin_data_path)\n",
    "                if os.path.isdir(os.path.join(origin_data_path, cla))]\n",
    "data_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "075bb836-103e-4ed2-9177-24d8f1f1f167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akiec\n",
      "bcc\n",
      "bkl\n",
      "df\n",
      "mel\n",
      "nv\n",
      "vasc\n"
     ]
    }
   ],
   "source": [
    "# Augmentation directory\n",
    "train_root = os.path.join(data_root,\"aug_train_8000\")\n",
    "mk_file(train_root)\n",
    "for cla in data_class:\n",
    "    mk_file(os.path.join(train_root, cla))\n",
    "for file in os.listdir(train_root):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ceea0cac-b8dd-4f87-87c7-2372bd8ae413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 292 images belonging to 1 classes.\n",
      "Found 458 images belonging to 1 classes.\n",
      "Found 979 images belonging to 1 classes.\n",
      "Found 103 images belonging to 1 classes.\n",
      "Found 991 images belonging to 1 classes.\n",
      "Found 5968 images belonging to 1 classes.\n",
      "Found 127 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Augmenting images and storing them in temporary directories \n",
    "for img_class in data_class:\n",
    "\n",
    "    #creating temporary directories\n",
    "    # creating a base directory\n",
    "    aug_dir = \"aug_dir\"   \n",
    "    # creating a subdirectory inside the base directory for images of the same class\n",
    "    img_dir = os.path.join(data_root, aug_dir, img_class)\n",
    "\n",
    "    mk_file(img_dir)\n",
    "    \n",
    "    cla_path = os.path.join(origin_data_path,img_class)\n",
    "    img_list = os.listdir(cla_path)\n",
    "\n",
    "    # Copy images from the class train dir to the img_dir \n",
    "    for index, image in enumerate(img_list):\n",
    "    # for file_name in img_list:\n",
    "\n",
    "        # path of source image in training directory\n",
    "        image_path = os.path.join(cla_path,image)\n",
    "\n",
    "        # creating a target directory to send images \n",
    "        tag_path = os.path.join(img_dir,image)\n",
    "\n",
    "        # copying the image from the source to target file\n",
    "        copy(image_path, tag_path)\n",
    "\n",
    "    # Temporary augumented dataset directory.\n",
    "    # img_dir\n",
    "\n",
    "    # Augmented images will be saved to training directory\n",
    "    save_path = os.path.join(train_root,img_class)\n",
    "\n",
    "    # Creating Image Data Generator to augment images\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest'\n",
    "\n",
    "    )\n",
    "\n",
    "    batch_size = 20\n",
    "\n",
    "    aug_datagen = datagen.flow_from_directory(directory=os.path.join(data_root, aug_dir),\n",
    "                                              save_to_dir=save_path,save_format='jpg',save_prefix='trans_',\n",
    "                                              target_size=(299, 299),batch_size=batch_size)\n",
    "\n",
    "    # Generate the augmented images\n",
    "    aug_images = 8000\n",
    "    \n",
    "    num_files = len(img_list)\n",
    "    num_batches = int(np.ceil((aug_images - num_files) / batch_size))\n",
    "\n",
    "    # creating 8000 augmented images per class\n",
    "    for i in range(0, num_batches):\n",
    "        images, labels = next(aug_datagen)\n",
    "\n",
    "    # delete temporary directory \n",
    "    rmtree(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71057845-b3a7-4c8d-9666-d4d64471f689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[akiec] processing [7520/7520]\n",
      "[bcc] processing [7528/7528]\n",
      "[bkl] processing [7033/7033]\n",
      "[df] processing [6795/6795]\n",
      "[mel] processing [6957/6957]\n",
      "[nv] processing [2040/2040]\n",
      "[vasc] processing [7152/7152]\n",
      "processing 45025 done!\n"
     ]
    }
   ],
   "source": [
    "# detect \n",
    "total_num = 0\n",
    "for cla in data_class:\n",
    "    cla_path = os.path.join(train_root, cla)\n",
    "    images = os.listdir(cla_path)\n",
    "    num = len(images)\n",
    "    total_num += num\n",
    "    for index, image in enumerate(images):\n",
    " \n",
    "        print(\"\\r[{}] processing [{}/{}]\".format(cla, index+1, num), end=\"\")  # processing bar\n",
    "    # break\n",
    "    print()\n",
    "\n",
    "print(f\"processing {total_num} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cfbb4b2-37ef-43e1-bae2-949468acb65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[akiec] processing [292/292]\n",
      "[bcc] processing [458/458]\n",
      "[bkl] processing [979/979]\n",
      "[df] processing [103/103]\n",
      "[mel] processing [991/991]\n",
      "[nv] processing [5968/5968]\n",
      "[vasc] processing [127/127]\n",
      "processing 8918 done!\n"
     ]
    }
   ],
   "source": [
    "# copy origin_data_path(8918) to train_root().\n",
    "total_num = 0\n",
    "for cla in data_class:\n",
    "\n",
    "    cla_path = os.path.join(origin_data_path, cla)\n",
    "    images = os.listdir(cla_path)\n",
    "    num = len(images)\n",
    "    total_num += num\n",
    "    for index, image in enumerate(images):\n",
    "        image_path = os.path.join(cla_path, image)\n",
    "        img_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        savepath = os.path.join(train_root, cla,img_name + \".jpg\")\n",
    "\n",
    "        img = Image.open(image_path)\n",
    "        img = img.resize((299, 299), resample=Image.LANCZOS)\n",
    "        img.save(savepath,quality=100)\n",
    "\n",
    "        print(\"\\r[{}] processing [{}/{}]\".format(cla, index+1, num), end=\"\")  # processing bar\n",
    "    # break\n",
    "    print()\n",
    "\n",
    "print(f\"processing {total_num} done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
