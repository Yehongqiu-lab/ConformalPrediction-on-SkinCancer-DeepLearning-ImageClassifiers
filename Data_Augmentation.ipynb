{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c952a3a-f0e7-458e-88db-b4f3c043095b",
   "metadata": {},
   "source": [
    "## Step 1:\n",
    "### Loading data into different directories based on its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab613b0e-c4d8-4e57-bac5-56fddeb09b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from shutil import copy, rmtree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e132e7-2f71-418c-977f-b9f22789be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e6f418f-9bcd-422a-bdf9-8896af318a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put this notebook in the same file where you put the metadata.csv and the image files \n",
    "train_df = pd.read_csv('train_metadata.csv') # the orginal file: HAM10000_metadata.csv, I changed its name for simplicity\n",
    "test_df = pd.read_csv('test_metadata.csv') # the orginal file:ISIC2018_Task3_Test_GroundTruth.csv, I changed its name for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6126640c-3b64-4f44-9400-5ead9ddbabdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "train_dir = os.path.join(cwd, 'train_dir')\n",
    "test_dir = os.path.join(cwd, 'test_dir')\n",
    "os.mkdir(train_dir)\n",
    "os.mkdir(test_dir)\n",
    "train_list = list(train_df['image_id'])\n",
    "test_list = list(test_df['image_id'])\n",
    "for i in targetnames:\n",
    "    directory1=train_dir+'/'+i\n",
    "    directory2=test_dir+'/'+i\n",
    "    os.mkdir(directory1)\n",
    "    os.mkdir(directory2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef24748c-dea3-47ff-a86d-482d802e99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.set_index('image_id', inplace=True)\n",
    "test_df.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f97a350-afb1-4e7e-9408-1f775b1c662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in train_list:\n",
    "    file_name = image+'.jpg'\n",
    "    label = train_df.loc[image, 'dx']\n",
    "\n",
    "    # path of source image\n",
    "    # I combined the orginal file ```HAM10000_images_part_1``` and ```HAM10000_images_part_2```,\n",
    "    # named the combined file as ```train```\n",
    "    source = os.path.join(cwd, 'train', file_name)   \n",
    "    if not os.path.exists(source):\n",
    "        print(f\"Image {file_name} not found. Skipping...\")\n",
    "        continue\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(train_dir, label, file_name)\n",
    "\n",
    "    copy(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79e3f5ff-3950-45f4-bfe6-3d6d88554092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ISIC_0035068.jpg not found. Skipping...\n"
     ]
    }
   ],
   "source": [
    "for image in test_list:\n",
    "    file_name = image+'.jpg'\n",
    "    label = test_df.loc[image, 'dx']\n",
    "\n",
    "    # path of source image\n",
    "    # I renamed the file ```ISIC2018_Task3_Test_Images``` as ```test```\n",
    "    source = os.path.join(cwd, 'test', file_name)\n",
    "    if not os.path.exists(source):\n",
    "        print(f\"Image {file_name} not found. Skipping...\")\n",
    "        continue\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(test_dir, label, file_name)\n",
    "\n",
    "    copy(source, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76790d0-0ebc-4641-9035-801d44501da3",
   "metadata": {},
   "source": [
    "## Step 2:\n",
    "### Split data into train set and val set\n",
    "### Data Augmentation on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c079d71-c609-4f31-a4f9-a7c6fa422f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from shutil import copy, rmtree \n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a325e5ea-cec6-4313-80c6-da74936fb4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_file(file_path: str):\n",
    "    if os.path.exists(file_path):\n",
    "        rmtree(file_path)\n",
    "    os.makedirs(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8301a1a-8c1d-4390-90f7-739eda4fb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "random.seed(0)\n",
    "split_rate = 0.11\n",
    "\n",
    "cwd = os.getcwd()\n",
    "data_root = os.path.abspath(os.path.join(cwd))\n",
    "origin_data_path_0 = os.path.join(data_root, \"train_dir\")\n",
    "assert os.path.exists(origin_data_path_0), \"path '{}' does not exist.\".format(origin_data_path_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1482ddbd-8ae4-4aaf-86b6-fe198c5d41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class = [cla for cla in os.listdir(origin_data_path_0)\n",
    "                if os.path.isdir(os.path.join(origin_data_path_0, cla))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c59d5ce6-7a8a-4e07-8fa1-30ea6ab7190b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42808d6f-8047-4af3-b0cd-0e64db10938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sm_root = os.path.join(data_root, \"train_sm_dir\")\n",
    "mk_file(train_sm_root)\n",
    "for cla in data_class:\n",
    "    mk_file(os.path.join(train_sm_root, cla))\n",
    "    \n",
    "val_root = os.path.join(data_root, \"val_dir\")\n",
    "mk_file(val_root)\n",
    "for cla in data_class:\n",
    "    mk_file(os.path.join(val_root, cla))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6e58906-8e97-4e10-a296-79d2a72a07b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[akiec] processing [327/327]\n",
      "[bcc] processing [514/514]\n",
      "[bkl] processing [1099/1099]\n",
      "[df] processing [115/115]\n",
      "[mel] processing [1113/1113]\n",
      "[nv] processing [6705/6705]\n",
      "[vasc] processing [142/142]\n",
      "processing 10015 done!\n"
     ]
    }
   ],
   "source": [
    "total_num = 0\n",
    "for cla in data_class:\n",
    "    cla_path = os.path.join(origin_data_path_0, cla)\n",
    "    images = os.listdir(cla_path)\n",
    "    num = len(images)\n",
    "    total_num += num\n",
    "    eval_index = random.sample(images, k=int(num*split_rate))\n",
    "    for index, image in enumerate(images):\n",
    "        if image in eval_index:\n",
    "            image_path = os.path.join(cla_path, image)\n",
    "            new_path = os.path.join(val_root, cla)\n",
    "            copy(image_path, new_path)\n",
    "        else:\n",
    "            image_path = os.path.join(cla_path, image)\n",
    "            new_path = os.path.join(train_sm_root, cla)\n",
    "            copy(image_path, new_path)\n",
    "        print(\"\\r[{}] processing [{}/{}]\".format(cla, index+1, num), end=\"\")  # processing bar\n",
    "    print()\n",
    "\n",
    "print(f\"processing {total_num} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e85d11d-d18e-4a64-b689-707896880ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source directory\n",
    "cwd = os.getcwd()\n",
    "data_root = os.path.abspath(os.path.join(cwd))\n",
    "origin_data_path = os.path.join(data_root, \"train_sm_dir\")\n",
    "assert os.path.exists(origin_data_path), \"path '{}' does not exist.\".format(origin_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fafca7d-1352-4f4e-9104-e5005fa9c028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_class = [cla for cla in os.listdir(origin_data_path)\n",
    "                if os.path.isdir(os.path.join(origin_data_path, cla))]\n",
    "data_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "075bb836-103e-4ed2-9177-24d8f1f1f167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akiec\n",
      "bcc\n",
      "bkl\n",
      "df\n",
      "mel\n",
      "nv\n",
      "vasc\n"
     ]
    }
   ],
   "source": [
    "# Augmentation directory\n",
    "train_root = os.path.join(data_root,\"aug_train_8000\")\n",
    "mk_file(train_root)\n",
    "for cla in data_class:\n",
    "    mk_file(os.path.join(train_root, cla))\n",
    "for file in os.listdir(train_root):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ceea0cac-b8dd-4f87-87c7-2372bd8ae413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 292 images belonging to 1 classes.\n",
      "Found 458 images belonging to 1 classes.\n",
      "Found 979 images belonging to 1 classes.\n",
      "Found 103 images belonging to 1 classes.\n",
      "Found 991 images belonging to 1 classes.\n",
      "Found 5968 images belonging to 1 classes.\n",
      "Found 127 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Augmenting images and storing them in temporary directories \n",
    "for img_class in data_class:\n",
    "\n",
    "    #creating temporary directories\n",
    "    # creating a base directory\n",
    "    aug_dir = \"aug_dir\"   \n",
    "    # creating a subdirectory inside the base directory for images of the same class\n",
    "    img_dir = os.path.join(data_root, aug_dir, img_class)\n",
    "\n",
    "    mk_file(img_dir)\n",
    "    \n",
    "    cla_path = os.path.join(origin_data_path,img_class)\n",
    "    img_list = os.listdir(cla_path)\n",
    "\n",
    "    # Copy images from the class train dir to the img_dir \n",
    "    for index, image in enumerate(img_list):\n",
    "    # for file_name in img_list:\n",
    "\n",
    "        # path of source image in training directory\n",
    "        image_path = os.path.join(cla_path,image)\n",
    "\n",
    "        # creating a target directory to send images \n",
    "        tag_path = os.path.join(img_dir,image)\n",
    "\n",
    "        # copying the image from the source to target file\n",
    "        copy(image_path, tag_path)\n",
    "\n",
    "    # Temporary augumented dataset directory.\n",
    "    # img_dir\n",
    "\n",
    "    # Augmented images will be saved to training directory\n",
    "    save_path = os.path.join(train_root,img_class)\n",
    "\n",
    "    # Creating Image Data Generator to augment images\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest'\n",
    "\n",
    "    )\n",
    "\n",
    "    batch_size = 20\n",
    "\n",
    "    aug_datagen = datagen.flow_from_directory(directory=os.path.join(data_root, aug_dir),\n",
    "                                              save_to_dir=save_path,save_format='jpg',save_prefix='trans_',\n",
    "                                              target_size=(299, 299),batch_size=batch_size)\n",
    "\n",
    "    # Generate the augmented images\n",
    "    aug_images = 8000\n",
    "    \n",
    "    num_files = len(img_list)\n",
    "    num_batches = int(np.ceil((aug_images - num_files) / batch_size))\n",
    "\n",
    "    # creating 8000 augmented images per class\n",
    "    for i in range(0, num_batches):\n",
    "        images, labels = next(aug_datagen)\n",
    "\n",
    "    # delete temporary directory \n",
    "    rmtree(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71057845-b3a7-4c8d-9666-d4d64471f689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[akiec] processing [7520/7520]\n",
      "[bcc] processing [7528/7528]\n",
      "[bkl] processing [7033/7033]\n",
      "[df] processing [6795/6795]\n",
      "[mel] processing [6957/6957]\n",
      "[nv] processing [2040/2040]\n",
      "[vasc] processing [7152/7152]\n",
      "processing 45025 done!\n"
     ]
    }
   ],
   "source": [
    "# detect \n",
    "total_num = 0\n",
    "for cla in data_class:\n",
    "    cla_path = os.path.join(train_root, cla)\n",
    "    images = os.listdir(cla_path)\n",
    "    num = len(images)\n",
    "    total_num += num\n",
    "    for index, image in enumerate(images):\n",
    " \n",
    "        print(\"\\r[{}] processing [{}/{}]\".format(cla, index+1, num), end=\"\")  # processing bar\n",
    "    # break\n",
    "    print()\n",
    "\n",
    "print(f\"processing {total_num} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cfbb4b2-37ef-43e1-bae2-949468acb65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[akiec] processing [292/292]\n",
      "[bcc] processing [458/458]\n",
      "[bkl] processing [979/979]\n",
      "[df] processing [103/103]\n",
      "[mel] processing [991/991]\n",
      "[nv] processing [5968/5968]\n",
      "[vasc] processing [127/127]\n",
      "processing 8918 done!\n"
     ]
    }
   ],
   "source": [
    "# copy origin_data_path(8918) to train_root().\n",
    "total_num = 0\n",
    "for cla in data_class:\n",
    "\n",
    "    cla_path = os.path.join(origin_data_path, cla)\n",
    "    images = os.listdir(cla_path)\n",
    "    num = len(images)\n",
    "    total_num += num\n",
    "    for index, image in enumerate(images):\n",
    "        image_path = os.path.join(cla_path, image)\n",
    "        img_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        savepath = os.path.join(train_root, cla,img_name + \".jpg\")\n",
    "\n",
    "        img = Image.open(image_path)\n",
    "        img = img.resize((299, 299), resample=Image.LANCZOS)\n",
    "        img.save(savepath,quality=100)\n",
    "\n",
    "        print(\"\\r[{}] processing [{}/{}]\".format(cla, index+1, num), end=\"\")  # processing bar\n",
    "    # break\n",
    "    print()\n",
    "\n",
    "print(f\"processing {total_num} done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec955bd6-82a7-4a8c-b4c0-a99099862a62",
   "metadata": {},
   "source": [
    "# Neglect the following:\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Load the training and test CSV files\n",
    "train_df = pd.read_csv(\"C:/Users/20878/221Project/HAM10K/HAM10000_metadata.csv\")\n",
    "test_df = pd.read_csv(\"C:/Users/20878/221Project/HAM10K/ISIC2018_Test_GroundTruth.csv\")\n",
    "\n",
    "train_image_paths = [\"C:/Users/20878/221Project/HAM10K/HAM10000_images_part_1/\" + img for img in train_df['image_id']\n",
    "                     + \".jpg\"]\n",
    "train_df['dx'] = pd.Categorical(train_df['dx'])\n",
    "train_df['dx_code'] = train_df['dx'].cat.codes\n",
    "train_labels = train_df['dx_code'].values\n",
    "\n",
    "mapping_dict = dict(enumerate(train_df['dx'].cat.categories))\n",
    "\n",
    "test_image_paths = [\"C:/Users/20878/221Project/HAM10K/ISIC2018_Test_Images/\" + img for img in test_df['image_id']\n",
    "                    + \".jpg\"]\n",
    "test_df['dx_code'] = test_df['dx'].map(mapping_dict)\n",
    "test_labels = test_df['dx_code'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e751b55-a0c4-4bfb-83c2-78adcf3b5266",
   "metadata": {},
   "source": [
    "# define the default transform:\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Define the custom Dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eb5606-7b26-4115-9d64-cf5aa922bd4c",
   "metadata": {},
   "source": [
    "# Create the full training dataset\n",
    "full_train_dataset = ImageDataset(image_paths=train_image_paths, labels=train_labels)\n",
    "# DataLoader to iterate through the dataset\n",
    "loader = DataLoader(full_train_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "# Initialize lists to store the mean and std for each RGB channel\n",
    "mean = 0.\n",
    "std = 0.\n",
    "nb_samples = 0.\n",
    "i = 0\n",
    "\n",
    "for images, _ in loader:\n",
    "    if i > 1: break\n",
    "    batch_samples = images.size(0)  # Number of images in the batch\n",
    "    print(batch_samples)\n",
    "    print(image.size())\n",
    "    images = images.view(batch_samples, images.size(1), -1)  # Flatten H and W\n",
    "    mean += images.mean(2).sum(0)  # Mean over pixels, sum over batch\n",
    "    std += images.std(2).sum(0)    # Std over pixels, sum over batch\n",
    "    nb_samples += batch_samples\n",
    "    i = i + 1\n",
    "mean /= nb_samples\n",
    "std /= nb_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17e2f66-ef0e-401e-9935-c0743d466be2",
   "metadata": {},
   "source": [
    "full_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c426d385-073c-4b67-9b2c-9cd77d011631",
   "metadata": {},
   "source": [
    "# Define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.75, 1.0), ratio=(0.8, 1.2)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=RGB_mean, std=RGB_std),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=RGB_mean, std=RGB_std),\n",
    "])\n",
    "\n",
    "test_transform = val_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39425aa-a5d8-486d-a01d-dc74d027d46c",
   "metadata": {},
   "source": [
    "# Split the dataset into training and validation sets (e.g., 80% train, 20% validation)\n",
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "# Set the transform for each subset\n",
    "train_dataset.full_train_dataset.transform = train_transform\n",
    "val_dataset.full_train_dataset.transform = val_transform\n",
    "\n",
    "# Create the test dataset\n",
    "test_dataset = ImageDataset(image_paths=test_image_paths, labels=test_labels, transform=test_transform)\n",
    "\n",
    "# Create DataLoaders for each set\n",
    "bs = 32\n",
    "shf = [True, False, False]\n",
    "nw = 2\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=shf[0], num_workers=nw)\n",
    "val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=shf[1], num_workers=nw)\n",
    "test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=shf[2], num_workers=nw)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
